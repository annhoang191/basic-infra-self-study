# S3 Overview
- A securable, durable and highly scalable object storage. It's for files, images, and webpages, etc 
- Simple to use with simple web service interface
- Scalable: allow you to store and retrieve any amount of data from anywhere on the web with very low cost
- It manages data as objects rather than file system or data blocks
=> can upload any type of files to s3: photo, videos, code, documents, text files
=> cannot be used to run an operating system or database
- Unlimited storage: the total volume of data and the number of objects you can store is unlimited
- Objects up to 5TB in size: s3 objects can range in size from a minimum of 0 bytes to a maximum of 5 tb
	- The largest object that can be uploaded in a single PUT is **5 gigabytes**. For objects larger than 100 megabytes, customers should consider using the Multipart Upload capability.
- S3 buckets: store files in buckets (similar to folders)
- S3 has universal namespace: all aws accounts share the s3 namépace. Each s3 bucket name is globally unique
- S3 url: https://bucket-name.s3.region.amazonaws.com/key-name
- Static website hosted by s3 url: Depending on your Region, your Amazon S3 website endpoint follows one of these two formats:
	- s3-website dash (-) Region ‐ `http://bucket-name.s3-website-Region.amazonaws.com`
	-  s3-website dot (.) Region ‐ `http://bucket-name.s3-website.Region.amazonaws.com`
- Upload file: when you upload file to s3 bucket you will retrieve an http 200 code if the upload is successful
- S3 object:
	- Key: the name of the object, eg: ralphie.jpg
	- value: the data itself which is made up of a sequence of bytes
	- version id: important for storing multiple versions of same object
	- metadata: data about the data you are storing, eg: content-type, last-modified

=> S3 is a safe place to store your files. The data is spread across multiple devices and facilities to ensure availability and durability
- S3 is built for 99.95% - 99.99% service availability depending on the s3 tier
- S3 is built for 99.999999999% durability for data stored in s3
- Secure data on s3
	- Server-side encryption: can set default encryption on a bucket to encrypt all new objects when they are stored in the bucket
	- Access Control List: define which aws accounts or groups are granted access and the type of access. You can attach s3 ACLs to individual objects within a bucket
	- Bucket policies: specify what actions are allowed or denied (eg: allow user Alice to PUT but not DELETE objects in the bucket)
	
	# S3 storage class
	## Standard
	- High availability and durability: data is stored redundantly across multiple devices in multiples facilities (>= 3 AZs)
		- 99.9% Availability
		- 99.999999999% Durability
	- Designed for frequent access data
	- Suitable for most workloads: the default storage class
	=> Used for websites, content distribution, mobile and gaming apps, big data analytics 
	=> The most expensive cost
	=> Only pay for storage fee, you don't pay any additional fees to access data
	## Standard-Infrequent Access
	- Designed for infrequently accessed data 
	- >= 3 AZs
	- 99.9% Availability
	- 99.999999999% Durability
	- Rapid access: used for data that is accessed less frequently but requires rapid access when needed
	- You pay to access the data: a low per GB storage price and a per GB retrieval fee
	=> Great for long-term storage, backups, data store for disaster recover files
	## One Zone-Infrequent Access
	- Like S3-IA
	- 99.5% Availability
	- 99.999999999% Durability
	- Data is stored redundantly within a single AZ
	- Cost 20% less than regular S3-IA
	=> Great for long-lived, infrequently accessed, non-critical data 
	=> Pay a retrieval fee
	## Glacier
	- >= 3 AZs
	- 99.99% availability
	- 99.999999999% durability
	- Very cheap storage
	- Optimized for data that is very infrequently accessed
	- Pay each time you access your data
	=> Use only for archiving data
	- 2 glacier options:
		- Glacier:
			- Provides long-term data archiving with retrieval times that range from 1 minute to 12 hours. eg: historical data only accessed a few times per year
		- Glacier deep archive
			- Archiving rarely accessed data with a default retrieval time of 12 hours. Eg: financial recorđs that maybe accessed once or twice per year
	## Intelligent-Tiering
	- >= 3 AZs
	- 99.9% availability
	- 99.999999999% durability
	- 2 tiers: frequent and infrequent access
	- Automatically moves your data to the most cost-effective tier based on how frequently you access each object
	- Monthly fee of $0.0025 per 1,000 objects
	=> Cost optimized for unknown access patterns
	
	# Secure S3 bucket
	- S3 is very secure by default: 
		- all newly created buckets are private
		- only the bucket owner can upload new files, read files, delete files, etc.
		- no public access by default
	=> Want to let other user have access to bucket? Use bucket policies
	=> Can setup access control to your buckets using bucket policies
	## Bucket policies
	- Applied at bucket level: permissions granted by the policy apply to all of the objects within the bucket
	- Not aplied to individual objects: cannot attach a bucket policy to an individual object
	- Group of files: a group of files which need to be accessed by the same people 
	- Written in json 
		```json
		{
			"Version: "2021-10-25",
			"Statement": [
				{
					"Sid": "PublicRead",
					"Effect": "Allow",
					"Principal": "*",
					"Action": ["s3:GetObject"],
					"Resource": ["arn:aws:s3::mybucket/**"]
				}
			]
		}
		```
		- Aws provides a policy generator tool to build out the policies you need
	## Bucket Access Control List (Bucket ACLs)
	- Access Control List are applied at an object level: we can apply different permissions for different objects within a bucket
	- Grant access to objects: can define which accounts or groups are granted access and also the type of access (read, write, or full control)
	- Fine grainted control: grant different type of access to different objects within the same bucket. eg: apply different permissions for different objects for different users and groups
## S3 access log
- Not be enabled by default
- Log all requests made to s3 bucket
- Logs written into another s3 bucket
## Exam tips
- S3 is secure by default
- Bucket policies: applied at a bucket level
- Access Control List: applied at an object level
- Access logs: s3 can be configured to create access logs which log all requests made to the s3 bucket

# S3 Encryption
## Encryption in transit
- Encrypt the data when you are sending it to and from your s3 bucket
- Done using SSL/TLS => use https to upload/download files 
## Encryption at rest - server side encryption
- Data is encrypted when it's stored on disk
- Files are encrypted when they are uploaded to s3
- 3 different types of server-side encryption
	- SSE-S3
		- Encrypt data using encryption key managed by S3
		- Each object is encrypted using its own unique key
		- They also encrypt the key itself with a master key which they rotate for you. All are handled by AWS
		- Algorithm: AES 256 bit-encryption
	- SSE-KMS
		- With the aws key management service. AWS manage the keys for us
		- Separate permissions for the use of an additional key called an envelope key - a key which encrypts your data's encryption key
		- Get an audit trail which records the use of your encryption key: see when your key has been used, who used it, and what they did
	- SSE-C
		- Customer provided keys
		- AWS manage the encryption and decryption activities
		- You manage your own keys
		- User are in charge of administer keys and rotating them
## Encryption at rest - client side encryption
- You encrypt the files yourself before you upload them to s3
- You can choose your own encryption method and encrypt the files before uploading them
## Enforcing server side encryption
- Use console: select the encryption setting on your s3 bucket => the easiest way
- Bucket policy: create a bucket policy which denies any S3 PUT request which doesn't include `x-amz-server-side-encryption` param in request header
- Example: Everytime a file is uploaded a PUT request is initiated
	- If the file is to be encrypted at upload time => a special param will be included in the PUT request header `x-amz-server-side-encryption`
	- Two options:
		- `x-amz-server-side-encryption:AES-256` (using SSE-S3 )
		- `x-amz-server-side-encryption: aws:kms` (using SSE-KMS)
	=> When this param is included in the header of PUT request, it tells S3 to encrypt the object at the time upload using specified method
	
	# CORS configuration for static websites hosted in S3
	- A way of allowing code that is in one S3 bucket to access or reference code that is in another S3 bucket
	- Create 2 buckets => Select properties tab of bucket #1 => copy endpoint url of the website which is blocked by cors and need to be accessed => go back to bucket #2 => selec permission tab => scroll down to CORS => Edit configuration
		```
		[
		{
			"AllowHeaders":[
				"Authorization"
			],
			"AllowMethods":[
				"GET"
			],
			"AllowedOrigins":[
				"https://origin_url/*"
			],
			"MaxAgeSeconds": 3000
		}
		]
		```